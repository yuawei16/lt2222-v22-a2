{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10c4c5b",
   "metadata": {},
   "source": [
    "# Assignment 2 - part-of-speech prediction from limited context\n",
    "\n",
    "In this assignment, you will train classifiers that attempt, within a window of five words, to make a binary prediction about whether the third word belongs to a given part of speech (noun, verb, adjective, adverb), but using very limited information -- that is, the last two letters of the first, second, fourth, and fifth word of the sequence, and no information whatsoever directly from the third word itself.  You will strip out all punctuation (using the NLTK `WordPunctTokenizer`), lowercase, and remove stop words (using the NLTK English stop words list).\n",
    "\n",
    "In other words, you will predict over samples that have two classes, P and not-P, where P is the selected part of speech to classify.  For example, from the sentence, \"The quick brown fox jumped over the lazy dog.\", we can select the following 5-word windows without stop words, \"brown fox jumped lazy dog\" and \"quick brown fox jumped lazy\".  If we select verbs as the part-of-speech we are classifying over, we get the instances <(wn,ox,zy,og),1>, since \"jumped\" is a verb, but <(ck,wn,ed,zy),0> because \"fox\" in that context is not.\n",
    "\n",
    "This means that you will need to take into account the position of the last-two-letter feature:  \"zy\" as the fourth word's last two letters is different from \"zy\" as the fifth word's last two letters.  They are two features, say, `zy_4` and `zy_5`.\n",
    "\n",
    "This will likely not actually work.  But it might!\n",
    "\n",
    "You will create training and testing samples according to this procedure, and you will build a data structure that can be fed to a support vector machine (SVM) classifier.  You will train the classifier on the training data and evaluate it on the testing data. \n",
    "\n",
    "The work will be done in a .py module file in the same folder as this notebook.  **No modifications to this notebook will be graded.** We will run your module using this notebook or one we modify that you won't see in order to test your code.\n",
    "\n",
    "The file you must create and add to the github repo is `mycode.py`, which will be imported here.  You can create your own notebooks or scripts to test it.  You can put any number of your own helper functions and also put optional parameters on any of the python functions mentioned here. You should also create a Markdown file, `notes.md`, to keep any **concise** notes and remarks about the assignment.  The code must run on mltgpu.\n",
    "\n",
    "**This assignment is due Monday, 2022 March 7, at 23:59. There are 33 points and 5 bonus points.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f0aee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mycode as mc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935014b0",
   "metadata": {},
   "source": [
    "## Part 0 - preparation (2 points)\n",
    "\n",
    "Fork this repository and create and add `mycode.py` and `notes.md`. \n",
    "\n",
    "## Part 1 - obtaining the text (3 points)\n",
    "\n",
    "You will randomly select the given number of lines from the gzipped file we give you (so you will have to figure out how to access gzipped text files).  Explain how you implemented the random selection in `notes.md`. When we run it, it should give a new sample every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32edcefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Following up on its participation in the World Conference Against Racism, the University has initiated \"Ubuntu -- Awakening the Spirit of Humanity\", a project involving intercultural exchange and dialogue leading to community-level educational and other values-based action.\\n',\n",
       " 'For further information, please contact the World Bank New York Office (tel. 1 (212) 355-5112).\\n',\n",
       " '17. Introducing document HR/MEX/SEM.1/2002/BP.7, Ms. Gilda Pacheco noted that, in accordance with the provisions on training and education adopted by the Conference against Racism, there are four major types of challenges for the human rights movement: those related to efforts to ensure better knowledge and use of existing international norms and mechanisms for combating racism and discrimination; those that facilitate the harmonization of national legislation and public policies with international standards, with the participation of directly affected populations; those aimed at strengthening the skills of the populations concerned and human rights bodies; and those related to awareness-raising and the provision of information to the general population.\\n',\n",
       " 'The Cameroonian specialized services also maintain a register of arms in the possession of foreign nationals.\\n',\n",
       " 'Distr.\\n',\n",
       " '6. Her delegation noted with concern that some of the posts approved by the General Assembly in resolution 56/248 to provide the two Tribunals with on-site audit and investigation services had not been filled.\\n',\n",
       " 'The strategy is to leverage financial resources from international and domestic sources to strengthen housing finance institutions and mechanisms and to support human settlements projects and programmes.\\n',\n",
       " '5. Commends the international community for the financial, technical and material support given to the Economic Community of Central African States;\\n',\n",
       " 'Procedures on on-going monitoring of accounts and transactions that include:\\n',\n",
       " '(Signed) Jeremy Greenstock\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_lines = mc.sample_lines(\"/scratch/UN-english.txt.gz\", lines=100000)\n",
    "sampled_lines[40000:40010]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc4e1b8",
   "metadata": {},
   "source": [
    "## Part 2 - creating the samples (7 points)\n",
    "\n",
    "From the sampled lines, you will then randomly create the five-word samples.\n",
    "\n",
    "You will tokenize the sentences and apply POS-tagging to them -- you need to do this before you create the samples, since POS-tagging needs context. You will then remove stop words and punctuation and lowercase the remainder.  Next, you will randomly, over the entire set of sentences, choose samples of five words in sequence, up to a certain limit.  You find the last two characters of the first, second, fourth, and fifth words, and create the type of structure specified up in the introduction to this assignment for each sample. The exact representation is up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a6c6272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('following', 'VBG'),\n",
       "  ('participation', 'NN'),\n",
       "  ('world', 'NN'),\n",
       "  ('conference', 'NN'),\n",
       "  ('racism', 'NN'),\n",
       "  ('university', 'NN'),\n",
       "  ('initiated', 'VBN'),\n",
       "  ('``', '``'),\n",
       "  ('ubuntu', 'JJ'),\n",
       "  ('--', ':'),\n",
       "  ('awakening', 'VBG'),\n",
       "  ('spirit', 'NN'),\n",
       "  ('humanity', 'NN'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('project', 'NN'),\n",
       "  ('involving', 'VBG'),\n",
       "  ('intercultural', 'JJ'),\n",
       "  ('exchange', 'NN'),\n",
       "  ('dialogue', 'NN'),\n",
       "  ('leading', 'VBG'),\n",
       "  ('community-level', 'JJ'),\n",
       "  ('educational', 'JJ'),\n",
       "  ('values-based', 'JJ'),\n",
       "  ('action', 'NN')],\n",
       " [('information', 'NN'),\n",
       "  ('please', 'NN'),\n",
       "  ('contact', 'VB'),\n",
       "  ('world', 'NN'),\n",
       "  ('bank', 'NN'),\n",
       "  ('new', 'JJ'),\n",
       "  ('york', 'NN'),\n",
       "  ('office', 'NN'),\n",
       "  ('tel', 'NN'),\n",
       "  ('1', 'CD'),\n",
       "  ('212', 'CD'),\n",
       "  ('355-5112', 'CD')],\n",
       " [('17.', 'CD'),\n",
       "  ('introducing', 'VBG'),\n",
       "  ('document', 'NN'),\n",
       "  ('hr/mex/sem.1/2002/bp.7', 'NN'),\n",
       "  ('ms.', 'FW'),\n",
       "  ('gilda', 'NN'),\n",
       "  ('pacheco', 'NN'),\n",
       "  ('noted', 'VBD'),\n",
       "  ('accordance', 'NN'),\n",
       "  ('provisions', 'NNS'),\n",
       "  ('training', 'NN'),\n",
       "  ('education', 'NN'),\n",
       "  ('adopted', 'VBN'),\n",
       "  ('conference', 'NN'),\n",
       "  ('racism', 'NN'),\n",
       "  ('four', 'CD'),\n",
       "  ('major', 'JJ'),\n",
       "  ('types', 'NNS'),\n",
       "  ('challenges', 'NNS'),\n",
       "  ('human', 'JJ'),\n",
       "  ('rights', 'NNS'),\n",
       "  ('movement', 'NN'),\n",
       "  ('related', 'VBN'),\n",
       "  ('efforts', 'NNS'),\n",
       "  ('ensure', 'VB'),\n",
       "  ('better', 'JJR'),\n",
       "  ('knowledge', 'NN'),\n",
       "  ('use', 'NN'),\n",
       "  ('existing', 'VBG'),\n",
       "  ('international', 'JJ'),\n",
       "  ('norms', 'NNS'),\n",
       "  ('mechanisms', 'NNS'),\n",
       "  ('combating', 'VBG'),\n",
       "  ('racism', 'NN'),\n",
       "  ('discrimination', 'NN'),\n",
       "  ('facilitate', 'VBP'),\n",
       "  ('harmonization', 'NN'),\n",
       "  ('national', 'JJ'),\n",
       "  ('legislation', 'NN'),\n",
       "  ('public', 'JJ'),\n",
       "  ('policies', 'NNS'),\n",
       "  ('international', 'JJ'),\n",
       "  ('standards', 'NNS'),\n",
       "  ('participation', 'NN'),\n",
       "  ('directly', 'RB'),\n",
       "  ('affected', 'JJ'),\n",
       "  ('populations', 'NNS'),\n",
       "  ('aimed', 'VBN'),\n",
       "  ('strengthening', 'VBG'),\n",
       "  ('skills', 'NNS'),\n",
       "  ('populations', 'NNS'),\n",
       "  ('concerned', 'VBN'),\n",
       "  ('human', 'JJ'),\n",
       "  ('rights', 'NNS'),\n",
       "  ('bodies', 'NNS'),\n",
       "  ('related', 'VBN'),\n",
       "  ('awareness-raising', 'JJ'),\n",
       "  ('provision', 'NN'),\n",
       "  ('information', 'NN'),\n",
       "  ('general', 'JJ'),\n",
       "  ('population', 'NN')],\n",
       " [('cameroonian', 'JJ'),\n",
       "  ('specialized', 'NN'),\n",
       "  ('services', 'NNS'),\n",
       "  ('also', 'RB'),\n",
       "  ('maintain', 'VBP'),\n",
       "  ('register', 'NN'),\n",
       "  ('arms', 'NNS'),\n",
       "  ('possession', 'NN'),\n",
       "  ('foreign', 'JJ'),\n",
       "  ('nationals', 'NNS')],\n",
       " [('distr', 'NN')],\n",
       " [('6.', 'CD'),\n",
       "  ('delegation', 'NN'),\n",
       "  ('noted', 'VBD'),\n",
       "  ('concern', 'NN'),\n",
       "  ('posts', 'NNS'),\n",
       "  ('approved', 'VBN'),\n",
       "  ('general', 'JJ'),\n",
       "  ('assembly', 'NN'),\n",
       "  ('resolution', 'NN'),\n",
       "  ('56/248', 'CD'),\n",
       "  ('provide', 'VB'),\n",
       "  ('two', 'CD'),\n",
       "  ('tribunals', 'NNS'),\n",
       "  ('on-site', 'JJ'),\n",
       "  ('audit', 'NN'),\n",
       "  ('investigation', 'NN'),\n",
       "  ('services', 'NNS'),\n",
       "  ('filled', 'VBN')],\n",
       " [('strategy', 'NN'),\n",
       "  ('leverage', 'VB'),\n",
       "  ('financial', 'JJ'),\n",
       "  ('resources', 'NNS'),\n",
       "  ('international', 'JJ'),\n",
       "  ('domestic', 'JJ'),\n",
       "  ('sources', 'NNS'),\n",
       "  ('strengthen', 'VB'),\n",
       "  ('housing', 'NN'),\n",
       "  ('finance', 'NN'),\n",
       "  ('institutions', 'NNS'),\n",
       "  ('mechanisms', 'NNS'),\n",
       "  ('support', 'VB'),\n",
       "  ('human', 'JJ'),\n",
       "  ('settlements', 'NNS'),\n",
       "  ('projects', 'NNS'),\n",
       "  ('programmes', 'NNS')],\n",
       " [('5.', 'CD'),\n",
       "  ('commends', 'VBZ'),\n",
       "  ('international', 'JJ'),\n",
       "  ('community', 'NN'),\n",
       "  ('financial', 'JJ'),\n",
       "  ('technical', 'JJ'),\n",
       "  ('material', 'JJ'),\n",
       "  ('support', 'NN'),\n",
       "  ('given', 'VBN'),\n",
       "  ('economic', 'JJ'),\n",
       "  ('community', 'NN'),\n",
       "  ('central', 'JJ'),\n",
       "  ('african', 'JJ'),\n",
       "  ('states', 'NNS')],\n",
       " [('procedures', 'NNS'),\n",
       "  ('on-going', 'JJ'),\n",
       "  ('monitoring', 'NN'),\n",
       "  ('accounts', 'NNS'),\n",
       "  ('transactions', 'NNS'),\n",
       "  ('include', 'VBP')],\n",
       " [('signed', 'VBN'), ('jeremy', 'NN'), ('greenstock', 'NN')]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_sentences = mc.process_sentences(sampled_lines)\n",
    "processed_sentences[40000:40010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c8bf857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('JJ', ['ed_0', 'sk_1', 'at_3', 'rt_4']), ('NN', ['sk_0', 'ar_1', 'rt_3', 'ns_4']), ('JJ', ['le_0', '16_1', 're_3', 'de_4']), ('NN', ['16_0', 'al_1', 'de_3', 'es_4']), ('NN', ['al_0', 're_1', 'es_3', 'nt_4']), ('VB', ['re_0', 'de_1', 'nt_3', 'gs_4']), ('NN', ['de_0', 'es_1', 'gs_3', 'ow_4']), ('NN', ['es_0', 'nt_1', 'ow_3', 'ge_4']), ('VB', ['nt_0', 'gs_1', 'ge_3', 'ed_4']), ('NN', ['gs_0', 'ow_1', 'ed_3', 'rt_4'])]\n"
     ]
    }
   ],
   "source": [
    "all_samples = mc.create_samples(processed_sentences, samples=50000)\n",
    "\n",
    "print(all_samples[25000:25010])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dcbea4",
   "metadata": {},
   "source": [
    "## Part 3 - convert the samples into a Pandas DataFrame (10 points)\n",
    "\n",
    "Here, you will take the samples and create a table whose columns are the features and the class and whose rows are the samples.  All the features and the class will be binary.  Note that there may be many columns, in the hundreds or thousands depending on the diversity of the final two consonants of the non-stop-words in the dataset, but the sum of all rows will be five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3304801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>VB</th>\n",
       "      <th>68_4</th>\n",
       "      <th>ea_4</th>\n",
       "      <th>ap_0</th>\n",
       "      <th>rk_3</th>\n",
       "      <th>r._4</th>\n",
       "      <th>ür_1</th>\n",
       "      <th>te_0</th>\n",
       "      <th>4_3</th>\n",
       "      <th>ez_3</th>\n",
       "      <th>...</th>\n",
       "      <th>dh_1</th>\n",
       "      <th>tá_4</th>\n",
       "      <th>na_3</th>\n",
       "      <th>07_4</th>\n",
       "      <th>ue_0</th>\n",
       "      <th>tc_3</th>\n",
       "      <th>mr_3</th>\n",
       "      <th>.g_4</th>\n",
       "      <th>gy_0</th>\n",
       "      <th>w-_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15_0</th>\n",
       "      <th>ng_1</th>\n",
       "      <th>en_3</th>\n",
       "      <th>ed_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ng_0</th>\n",
       "      <th>rk_1</th>\n",
       "      <th>ed_3</th>\n",
       "      <th>15_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rk_0</th>\n",
       "      <th>en_1</th>\n",
       "      <th>15_3</th>\n",
       "      <th>18_4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15_0</th>\n",
       "      <th>18_1</th>\n",
       "      <th>ld_3</th>\n",
       "      <th>ur_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18_0</th>\n",
       "      <th>pe_1</th>\n",
       "      <th>ur_3</th>\n",
       "      <th>ee_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pe_0</th>\n",
       "      <th>ld_1</th>\n",
       "      <th>ee_3</th>\n",
       "      <th>ed_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">al_0</th>\n",
       "      <th>ic_1</th>\n",
       "      <th>ts_3</th>\n",
       "      <th>nt_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts_1</th>\n",
       "      <th>ed_3</th>\n",
       "      <th>rs_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts_0</th>\n",
       "      <th>nt_1</th>\n",
       "      <th>rs_3</th>\n",
       "      <th>al_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nt_0</th>\n",
       "      <th>ed_1</th>\n",
       "      <th>al_3</th>\n",
       "      <th>us_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 2347 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     VB  68_4  ea_4  ap_0  rk_3  r._4  ür_1  te_0  4_3  ez_3  \\\n",
       "15_0 ng_1 en_3 ed_4   0     0     0     0     0     0     0     0    0     0   \n",
       "ng_0 rk_1 ed_3 15_4   0     0     0     0     0     0     0     0    0     0   \n",
       "rk_0 en_1 15_3 18_4   1     0     0     0     0     0     0     0    0     0   \n",
       "15_0 18_1 ld_3 ur_4   0     0     0     0     0     0     0     0    0     0   \n",
       "18_0 pe_1 ur_3 ee_4   0     0     0     0     0     0     0     0    0     0   \n",
       "pe_0 ld_1 ee_3 ed_4   0     0     0     0     0     0     0     0    0     0   \n",
       "al_0 ic_1 ts_3 nt_4   0     0     0     0     0     0     0     0    0     0   \n",
       "     ts_1 ed_3 rs_4   0     0     0     0     0     0     0     0    0     0   \n",
       "ts_0 nt_1 rs_3 al_4   0     0     0     0     0     0     0     0    0     0   \n",
       "nt_0 ed_1 al_3 us_4   0     0     0     0     0     0     0     0    0     0   \n",
       "\n",
       "                     ...  dh_1  tá_4  na_3  07_4  ue_0  tc_3  mr_3  .g_4  \\\n",
       "15_0 ng_1 en_3 ed_4  ...     0     0     0     0     0     0     0     0   \n",
       "ng_0 rk_1 ed_3 15_4  ...     0     0     0     0     0     0     0     0   \n",
       "rk_0 en_1 15_3 18_4  ...     0     0     0     0     0     0     0     0   \n",
       "15_0 18_1 ld_3 ur_4  ...     0     0     0     0     0     0     0     0   \n",
       "18_0 pe_1 ur_3 ee_4  ...     0     0     0     0     0     0     0     0   \n",
       "pe_0 ld_1 ee_3 ed_4  ...     0     0     0     0     0     0     0     0   \n",
       "al_0 ic_1 ts_3 nt_4  ...     0     0     0     0     0     0     0     0   \n",
       "     ts_1 ed_3 rs_4  ...     0     0     0     0     0     0     0     0   \n",
       "ts_0 nt_1 rs_3 al_4  ...     0     0     0     0     0     0     0     0   \n",
       "nt_0 ed_1 al_3 us_4  ...     0     0     0     0     0     0     0     0   \n",
       "\n",
       "                     gy_0  w-_3  \n",
       "15_0 ng_1 en_3 ed_4     0     0  \n",
       "ng_0 rk_1 ed_3 15_4     0     0  \n",
       "rk_0 en_1 15_3 18_4     0     0  \n",
       "15_0 18_1 ld_3 ur_4     0     0  \n",
       "18_0 pe_1 ur_3 ee_4     0     0  \n",
       "pe_0 ld_1 ee_3 ed_4     0     0  \n",
       "al_0 ic_1 ts_3 nt_4     0     0  \n",
       "     ts_1 ed_3 rs_4     0     0  \n",
       "ts_0 nt_1 rs_3 al_4     0     0  \n",
       "nt_0 ed_1 al_3 us_4     0     0  \n",
       "\n",
       "[10 rows x 2347 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf = mc.create_df(all_samples)\n",
    "fulldf[25000:25010]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69dd364",
   "metadata": {},
   "source": [
    "## Part 4 - extract training and testing sets (3 points)\n",
    "\n",
    "Here, you will create the training and testing datasets in order to train the model.  This will be based on a test percentage.  Round up if the percentage does not divide evenly into the sample size.  You will need to separate the class column into the y-values for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4aca7096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38553, 38553, 9639, 9639)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = mc.split_samples(fulldf, test_percent=20)\n",
    "len(train_X), len(train_y), len(test_X), len(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040b1a95",
   "metadata": {},
   "source": [
    "## Part 5 - train models (3 points)\n",
    "\n",
    "You will then train and return two support vector machine (SVM) models using the sklearn SVC class.  You should allow a choice between linear and radial basis function kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1ba3108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SVC(C=1, decision_function_shape='ovo', kernel='linear'),\n",
       " SVC(C=1, decision_function_shape='ovo', gamma=1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linear = mc.train(train_X, train_y, kernel='linear')\n",
    "model_rbf = mc.train(train_X, train_y, kernel=\"rbf\")\n",
    "model_linear, model_rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b6ed2",
   "metadata": {},
   "source": [
    "## Part 6 - evaluate the models (5 points)\n",
    "\n",
    "You will calculate and print precision, recall, and F-measure for the models on the test data. In `notes.md`, write down your comparison of these simple measures on the two models and any thoughts you might have on what they mean. (It could be very short, and since the samples do not stay stable between runs, you can save the evaluation scores in `notes.md` too.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9f892bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90      7838\n",
      "           1       0.48      0.04      0.07      1801\n",
      "\n",
      "    accuracy                           0.81      9639\n",
      "   macro avg       0.65      0.51      0.48      9639\n",
      "weighted avg       0.75      0.81      0.74      9639\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90      7838\n",
      "           1       0.71      0.00      0.01      1801\n",
      "\n",
      "    accuracy                           0.81      9639\n",
      "   macro avg       0.76      0.50      0.45      9639\n",
      "weighted avg       0.79      0.81      0.73      9639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mc.eval_model(model_linear, test_X, test_y)\n",
    "mc.eval_model(model_rbf, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0d840",
   "metadata": {},
   "source": [
    "## Part Bonus - try another sort of model from sklearn (5 points)\n",
    "\n",
    "Write a separate, command-line script (not a notebook) uses `mycode.py` to do all of the above, except that it trains a non-SVM classifier model.  Any non-trivial model available in sklearn will do. Explain how to run your code and the results of your own evaluation in `notes.md`, including any observations or opinions you may have on the classifier method you used in comparison to SVM.\n",
    "\n",
    "## Submission\n",
    "\n",
    "Push to your fork of the GitHub repository (which must be made public) and submit the URL of your repository in Canvas.  You can submit this notebook with the output from your run, as long as you do not modify the code or text in it without permission from us.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
